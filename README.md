# ETL-Using-AWS-Services

# AWS Data Engineering Pipeline (Kafka â†’ S3 â†’ Glue â†’ Athena â†’ Power BI)

## ğŸš€ Architecture
1. **Kafka â†’ S3 (raw-data-24-08)**  
   - Weather + Stocks raw data stored.  

2. **Glue Crawlers**  
   - `weather_crawler` â†’ raw weather data  
   - `stocks_crawler` â†’ raw stocks data  

3. **Glue ETL Jobs**  
   - `weather_transform` â†’ process raw â†’ curated parquet (`ready-weather/`)  
   - `stocks_transform` â†’ process raw â†’ curated parquet (`ready-stocks/`)  

4. **Athena**  
   - Query raw + curated data  

5. **Power BI**  
   - Connects to curated-data-24-08 or use Python export scripts to CSV.  

---

## ğŸ—‚ï¸ Folder Structure
- `glue-scripts/` â†’ Glue ETL jobs (PySpark scripts)  
- `powerbi/` â†’ Power BI integration scripts  
- `s3-buckets/` â†’ Documentation of raw + curated storage layout  

---

## ğŸ”§ Glue Scripts
- `weather_transform.py` â†’ Cleans and transforms raw weather data â†’ curated parquet  
- `stocks_transform.py` â†’ Cleans and transforms raw stocks data â†’ curated parquet  

---

## ğŸ”— Power BI Connection
Option 1: Connect Power BI directly to Athena.  
Option 2: Run export scripts to convert parquet â†’ CSV:
- `export_weather_csv.py`  
- `export_stocks_csv.py`  
